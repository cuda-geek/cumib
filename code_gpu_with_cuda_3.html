<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>Code GPU with CUDA</title>

    <meta name="description" content="CUDA cource: Code GPU with CUDA">
    <meta name="author" content="cuda.geek">
    <meta name="apple-mobile-web-appable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="3dparty/reveal/css/reveal.css">
    <link rel="stylesheet" href="stylesheets/cuda.geek.css" id="theme">
    <link rel="stylesheet" href="stylesheets/cuda.css">
    <link rel="stylesheet" href="3dparty/reveal/lib/css/zenburn.css">
    <script>
      document.write( '<link rel="stylesheet" href="3dparty/reveal/css/print/' + ( window.location
        .search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
    </script>
    <!--[if lt IE 9]>
      <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>
    <div class="reveal">
      <div class="slides">

        <section>
          <h1>Code GPU with CUDA</h1>
          <h2>Device code optimization principle</h2>
          <h3></h3>
          <br>
          <br>
          <br>
          <small>Created by Marina Kolpakova (
            <a href="http://github.com/cuda-geek">cuda.geek</a>
            ) for
            <a href="http://itseez.com">Itseez</a>
          </small>
          <h4><a href="code_gpu_with_cuda_2.html#/end1">previous</a></h4>
        </section>

        <section>
          <section>
            <h2>Outline</h2>
            <ul>
              <li>Optimization principle</li>
              <li>Performance limiters</li>
              <li>Little&#8217;s law</li>
              <li>TLP &amp; ILP</li>
            </ul>
          </section>
        </section>

        <section id="sec_0_0">
          <h2>Device code optimization principle</h2>
          <p>Specific of SIMT architecture makes GPU to be latent at all, so </p>
          <blockquote style="width:100%" cite="http://searchservervirtualization.techtarget.com/definition/Our-Favorite-Technology-Quotations">
          Hiding latency is the only GPU-specific optimization principle
          </blockquote>
          <br>
          <ul class="none">
            <li>Typical latencies for Kepler generation
              <ul>
                <li>register writeback: ~10 cycles</li>
                <li>L1: ~34 cycles</li>
                <li>Texture L1: ~96 cycles</li>
                <li>L2: ~160 cycles</li>
                <li>Global memory: ~350 cycles</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>Performance limiters</h2>
          <p>Optimize for GPU <b><mrow><mo>&#x2243;</mo></mrow></b> Optimize for <b>latency</b><br/>
          <p>Factors that pervert latency hiding:</p>
          <ul>
            <li>Insufficient parallelism</li>
            <li>Inefficient memory accesses</li>
            <li>Inefficient control flow</li>
          </ul>
        </section>

        <section>
          <h2>Throughput &amp; Latency</h2>
          <dl style="text-align:left;">
            <dt ><b>Throughput</b></dt>
            <dd style="margin-left: 4em;">is how many operations are performed in one cycle</dd>
            <dt><b>Latency</b></dt>
            <dd style="margin-left: 4em;">is how many cycles pipeline stalls before another dependent operation</dd>
            <dt><b>Inventory</b></dt>
            <dd style="margin-left: 4em;">is a number of warps on fly i.e. in execution stage of the pipeline</dd>
          </dl>
        </section>

        <section>
          <h2>Little&#8217;s law</h2>
          <blockquote cite="http://searchservervirtualization.techtarget.com/definition/Our-Favorite-Technology-Quotations">
            <b>
              <mrow>
                <mo>L</mo>
                <mo>=</mo>
                <mi>&#x3bb;<!--GREEK SMALL LETTER LAMDA--></mi>
                &times;
                <mo>W</mo>
              </mrow>
            </b>
            <br/>
            <p>Inventory (L) = Throughput (<mrow><mi>&#x3bb;<!--GREEK SMALL LETTER LAMDA--></mi></mrow>) &times; Latency (W)</p>
          </blockquote>
          <img src="images/c2/little.svg" width="50%" class="simple">
          <small>Example: GPU with 8 operations per clock and 18 clock latency </small>
        </section>

        <section>
          <h2>Little&#8217;s law: FFMA example</h2>
          <ul class="none">
            <li><b>Fermi</b> GF100
              <ul>
                <li>Throughput: 32 operations per clock (1 warp)</li>
                <li>Latency: ~18 clocks</li>
                <li>Maximum resident warps per SM: 24</li>
                <li>Inventory: 1 * 18 = <b>18 warps</b> on fly</li>
              </ul>
            </li>
            <li><b>Kepler</b> GK110
              <ul>
                  <li>Throughput: 128 (if no ILP) operations per clock (4 warps)</li>
                  <li>Latency: ~10 clocks</li>
                  <li>Maximum resident warps per SM: 64</li>
                  <li>Inventory: 4 * 10 = <b>40 warps</b> on fly</li>
              </ul>
            </li>
            <li><b>Maxwell</b> GM204
              <ul>
                <li>Throughput: 128 operations per clock (4 warps)</li>
                <li>Latency: ~6 clocks</li>
                <li>Maximum resident warps per SM: 64</li>
                <li>Inventory: 4 * 6 = <b>24 warps</b> on fly</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>TLP &amp; ILP</h2>
          <ul class="none">
            <li><b>T</b>hread <b>L</b>evel <b>P</b>arallelism
              <ul>
                <li>enabling factors:
                  <ul>
                    <li>sufficient number of warps per SM on fly</li>
                  </ul>
                </li>
                <li>limiting factors:
                  <ul>
                    <li>bad launch configuration</li>
                    <li>resource consuming kernels</li>
                    <li>poorly parallelized code</li>
                  </ul>
                </li>
              </ul>
            </li>
            <li><b>I</b>nstruction <b>L</b>evel <b>P</b>arallelism
              <ul>
                <li>enabling factors:
                  <ul>
                    <li>independent instructions per warp</li>
                    <li>dual issue capabilities</li>
                  </ul>
                </li>
                <li>limiting Factors:
                  <ul>
                    <li>structural hazards</li>
                    <li>data hazards</li>
                  </ul>
                </li>
              </ul>

            </li>
          </ul>
        </section>

        <section>
          <h2>Improving TLP</h2>
          <dl style="text-align:left;">
            <dt ><b>Occupancy</b></dt>
            <dd style="margin-left: 4em; text-align:justify;">is actual number of warps running concurrently on a multiprocessor divided by maximum number
            of warps that can be run concurrently by hardware</dd>
            <dt><b>Improve occupancy to achieve better TLP</b></dt>
          </dl>
          <br/>
          <ul>
            <li>Modern GPUs can keep up to 64 resident warps belonging to 16(Kepler)/32(Maxwell) blocks BUT you need recourses for them: registers, smem</li>
            <li>Kepler has 64&thinsp;K. &times; 32-bit registers and 32-lane wide warp</li>
          </ul>
          <blockquote cite="http://searchservervirtualization.techtarget.com/definition/Our-Favorite-Technology-Quotations" style="width:100%; margin-top:1em;">
            <p>65536
              <small style="vertical-align:bottom;">registers</small>
               / 64
              <small style="vertical-align:bottom;">warps</small>
               / 32
              <small style="vertical-align:bottom;">warp_size</small>
               =
              <b>32
                <small style="vertical-align:bottom;">registers / thread</small>
              </b>
            </p>
          </blockquote>
        </section>

<!--         <section>
          <h2>Adjust configuration</h2>
          <b>Block configuration itself can affect occupancy.</b>
          <img class="simple" src="images/c2/block_conf.svg" width="80%">
          <ul>
            <li>Number of threads per threadblock</li>
            <li>Number of threadblocks</li>
            <li>Amount of work per threadblock</li>
          </ul>
        </section> -->

        <section>
          <h2>Improving ILP</h2>
          <ul>
            <li><b>Kernel unrolling</b>: process more elements by thread, because operations on different elements are independent
            <pre width="100%"><code class="cpp"><span class="keyword">__global__</span> void unrolled(const float* in, float* out )
{
  const int tid = blockDim.x * blockIdx.x + threadIdx.x;
  const int totalThrads = blockDim.x * gridDim.x;
  out[tid]               = process(in[tid]);
  out[tid + totalThrads] = process(in[tid + totalThrads]);
}
</code></pre>
            </li>
            <li>Device code compiler is not bad in instruction reordering</li>
            <li><b>Loop unrolling</b> in device code to increase number of independent operations
            <pre width="100%"><code class="cpp">#pragma unroll CONST_EXPRESSION
for( int i = 0; i < N_ITERATIONS; i++ ) { /* ... */ }
</code></pre></li>
            <li>Other techniques used for increasing ILP on CPU are suitable</li>
          </ul>
        </section>

        <section>
          <h2>ILP on modern GPU<small>s</small></h2>
          <p>ILP is a mast-have for older architectures, but still help to hide pipeline latencies on modern GPUs</p>
          <ul>
            <li>Maxwell: 4 warp schedulers dual-issue each. 128 compute cores process up to 4 warps each clock. Compute cores utilization: <b>1.0</b> </li>
            <li>Kepler: 4 warp schedulers, dual-issue each. 192 compute cores process up to 6 warps each clock.
            If there is no ILP only 128 of 192 cores are used. Compute cores utilization: <b>0.6(6)</b></li>
            <li>Fermi (sm_21): 2 warp schedulers, dual-issue each. 48 compute cores process 3 warps each 2 clock.
            If there is no ILP only 32 of 48 cores are used. Compute cores  utilization: <b>0.6(6)</b></li>         
          </ul>
        </section>

          <section>
          <h2>Final words</h2>
          <ul class="none">
            <li>GPU optimization principles:
              <ul class="none">
                <li>Principle #1: hide latency</li>
                <li>Principle #2: see principle #1</li>
              </ul>
            </li>
          </ul>
        </section>

        <section id="end1">
          <h1>THE END</h1>
          <h6><a href="code_gpu_with_cuda_4.html">next</a></h6>
          <br>
          <br>
          <br>
          <h3>BY <a href="https://github.com/cuda-geek">cuda.geek</a> / 2013&ndash;2015</h3>
        </section>

      </div>
    </div>
    <script src="3dparty/reveal/lib/js/head.min.js"></script>
    <script src="3dparty/reveal/js/reveal.min.js"></script>
    <script>
            Reveal.initialize({
                controls: true,
                progress: true,
                history: true,
                center: false,
                rollingLinks: false,

                theme: Reveal.getQueryHash().theme,
                transition: Reveal.getQueryHash().transition || 'concave', // default/cube/page/concave/zoom/linear/fade/none
                dependencies: [
                    { src: '3dparty/reveal/lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: '3dparty/reveal/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: '3dparty/reveal/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: '3dparty/reveal/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: '3dparty/reveal/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: '3dparty/reveal/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
                    // { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
                    // { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
                ]
            });
    </script>
  </body>
</html>
