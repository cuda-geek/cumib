<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <title>Code GPU with CUDA</title>
    <meta name="description" content="Code GPU with CUDA - NVIDIA GPU Architecture">
    <meta name="author" content="Marina Kolpakova (cuda.geek)">
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="plugin/reveal/css/reveal.css">
    <link rel="stylesheet" href="plugin/reveal/css/theme/geek.css" id="theme">
    <link rel="stylesheet" href="css/colors-green.css">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="plugin/reveal/lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'plugin/reveal/css/print/pdf.css' : 'plugin/reveal/css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!--[if lt IE 9]>
    <script src="plugin/reveal/lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>
    <div class="reveal">
      <div class="slides">

        <section>
          <h1>Code GPU with CUDA</h1>
          <h2>Memory subsystem</h2>
          <h3></h3>
          <br>
          <br>
          <br>
          <small>Created by Marina Kolpakova (
            <a href="http://github.com/cuda-geek">cuda.geek</a>
            ) for
            <a href="http://itseez.com">Itseez</a>
          </small>
          <h6><small><a href="code_gpu_with_cuda_3.html#/end1">previous</a></small></h6>
        </section>

        <section>
          <section>
            <h2>Outline</h2>
            <ul>
              <li>GPU memory types</li>
              <li>Vector transaction</li>
              <li>Coalesced memory access</li>
              <li>Memory hierarchy</li>
              <li>request trajectory</li>
              <li>Hardware supported atomics</li>
              <li>Texture, constant, shared memory types</li>
              <li>Register spilling</li>
            </ul>
          </section>
          <section>
            <h2>Out of scope</h2>
            <ul>
              <li>Computer graphics capabilities</li>
              <li>Organization of texture interpolation HW</li>
            </ul>
          </section>
        </section>

        <section>
          <h2>GPU memory types</h2>
          <ul class="none">
            <li><strong><b>On-chip</b> is placed on SM</strong>
              <ul>
                <li>Register file (RF)</li>
                <li>Shared (SMEM)</li>
              </ul>
            </li>
            <li><strong><b>Off-chip</b> is placed in GPU&#8217;s RAM</strong>
              <ul>
                <li>Global (GMEM)</li>
                <li>Constant (CMEM)</li>
                <li>Texture (TEX)</li>
                <li>Local (LMEM)</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>Vector transaction</h2>
          <ul>
            <li>SM has dedicated LD/ST units to handle memory access</li>
            <li>Global memory accesses are serviced on warp basis</li>
          </ul>
        </section>

        <section>
          <h2>Coalesced memory access</h2>
          <ul>
            <li>Fist sm_10 defines coalesced access as an affine access aligned to 128 byte line
              <img src="images/c1/coalesced.svg" width="100%" class="simple">
            </li>
            <li>Other obsolete sm_1x has strict coalescing rules, too.
            </li>
            <li>Modern GPUs have more relaxed requirements and define coalesced transaction as
            transaction that <b>fits cache line</b>
              <img src="images/c1/still_coalesced.svg" class="simple">
            </li>
          </ul>
        </section>

        <section>
          <h2>Coalesced memory access (cont)</h2>
          <ul>
            <li><b>Request is coalesced if warp loads only bytes it needs</b></li>
            <li>The less cache lines it needs the more coalesced access it has</li>
            <li>Address alignment by cache line size is still preferred
              <img src="images/c1/unaligned.svg" class="simple">
            </li>
          </ul>
        </section>

        <section>
          <h2>Memory hierarchy</h2>
          <p>GPU memory has 2 levels of caches.</p>
          <img src="images/c1/gk107b.jpg" width="50%">
        </section>

        <section>
          <h2>Cache characteristics</h2>
          <table class="tbl1" style="width:100%">
            <colgroup>
              <col></col>
              <col></col>
              <col></col>
              <col></col>
              <col></col>
            </colgroup>
            <thead>
              <tr>
                <th>Cache</th>
                <th colspan="2">L1</th>
                <th colspan="2">L2</th>
              </tr>
              <tr>
                <th>generation</th>
                <th>Fermi</th>
                <th>Kepler</th>
                <th>Fermi</th>
                <th>Kepler</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>sizes, KB</td>
                <td>16/48</td>
                <td>16/32/48</td>
                <td>up to 768</td>
                <td>up to 1536</td>
              </tr>
              <tr>
                <td>line width</td>
                <td colspan="2">128B</td>
                <td colspan="2">32B</td>
              </tr>
              <tr>
                <td>latency</td>
                <td>56 clock</td>
                <td>-</td>
                <td>282</td>
                <td>158</td>
              </tr>
              <tr>
                <td>mode</td>
                <td>R, n-c</td>
                <td>-</td>
                <td colspan="2">R&amp;W, c, WB</td>
              </tr>
              <tr>
                <td>associativity</td>
                <td>2x64/6x64</td>
                <td>-</td>
                <td>?</td>
                <td>?</td>
              </tr>
              <tr>
                <td>usage</td>
                <td>gmem, sys</td>
                <td>sys</td>
                <td colspan="2">gmem, sys, tex</td>
              </tr>
            </tbody>
          </table>
        </section>

        <section>
          <h2>Memory request trajectory: LD.E</h2>
          <ul style="list-style-type: none;">
            <li><b>Fermi: fully-cached load</b>
              <ul style="margin-left: 65px;">
                <li>LD/ST units compute physical address and number of cache lines warp requests (L1 line is 128&thinsp;B)</li>
                <li>L1 hit -&gt; return line else go to L2</li>
                <li>L2 subdivides 128&thinsp;B line into 4x32&thinsp;B (L2 line size). If all required 32&thinsp;B lines are found in L2 return result else
                go to gmem</li>
                <li>gmem</li>
              </ul>
            </li>
            <li class="space-before"><b>Kepler</b>
              <ul style="margin-left: 65px;">
                <li>discrete GPUs: like Fermi but bypass L1</li>
                <li>integrated GPUs: the same as Fermi</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>duality of cache line</h2>
          <p>The following requests are equal from gmem point of view.</p>
          <img src="images/c1/2_transactions.svg" class="simple">
          <img src="images/c1/5_small.svg" class="simple">
          <p>32&thinsp;B granularity useful if access pattern is close to random.</p>
        </section>

        <section>
          <h2>Load Caching configurations</h2>
          <ul style="list-style-type: none;">
            <li><b>LD</b>
              <ul style="margin-left: 65px;">
                <li>Default (cache all): <b>No special suffix</b>
                  <pre><code class="avrasm"><span class="keyword">LD</span> R8, [R6];</code></pre>
                </li>
                <li>Cache only in L2 (cache global): <b>LD.CG</b>
                  <pre><code class="avrasm">LD.CG R4, [R16];</code></pre>
                </li>
                <li>Bypass caches (cache volatile) <b>LD.CV</b>
                  <pre><code class="avrasm"><span class="keyword">LD.CV</span> R14, [R14];</code></pre>
                </li>
                <li>Cache streaming</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>Memory request trajectory: ST.E</h2>
          <ul>
            <li>Store instruction invalidates cache line in L1 on all SMs, if present (since L1s are on SM and non-coherent)</li>
            <li>Request goes directly to L2. Default write strategy is <b>write back</b>. Can be configured
              as write through.</li>
            <li>Hit to L2 costs ~160 clocks in case write-back is not needed.</li>
            <li>Go to gmem in case of L2 miss (penalty > 350 clocks)</li>
          </ul>
          <small>L2 is multi-ported</small>
        </section>

        <section>
          <h2>Wide &amp; narrow types</h2>
          <ul style="list-style-type: none;"><li><b>Wide</b>
              <ul style="margin-left: 65px;">
                <li>GPU supports wide memory transactions
                  <pre><code class="avrasm">/*1618*/    LD.E.<b>128</b> R8, [R14];
/*1630*/    ST.E.<b>128</b> [R18], R8;</code></pre>
                </li>
                <li>Only 64 and 128-bit transactions are supported since they can be mapped to 2(4) 32-bit registers</li>
              </ul>
            </li>
            <li class="space-before"><b>Narrow</b>
              <ul style="margin-left: 65px;">
                <li><p>Example: uchar2 SOA store results in 2 store transactions</p>
                  <pre><code class="cpp">struct uchar2{
unsigned char x;
unsigned char y;
}</code></pre>
<pre><code class="avrasm">/*02c8*/    ST.E.U8 [R6+0x1], R0;
/*02d0*/    ST.E.U8 [R6], R3;</code></pre>
                </li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>GMEM Atomic operations</h2>
          <p>Performed in L2 per 32&thinsp;B cache line.</p>
          <table class="tbl1" style="width:100%">
            <colgroup>
              <col></col>
              <col></col>
              <col></col>
            </colgroup>
            <thead>
              <tr>
                <th>throughput</th>
                <th>Fermi, per clock</th>
                <th>Kepler, per clock</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>shared address</td>
                <td>1/9&thinsp;th</td>
                <td>1</td>
              </tr>
              <tr>
                <td>independent</td>
                <td>24</td>
                <td>64</td>
              </tr>
            </tbody>
          </table>
          <p>Same address means the same cache line</p>
          <ul>
            <li>ATOM<pre style="width:100%;"><code class="avrasm"><span class="keyword">ATOM</span>.E.INC R4, [R6], R8;</code></pre></li>
            <li>RED<pre style="width:100%;"><code class="avrasm"><span class="keyword">RED</span>.E.ADD [R2], R0;</code></pre></li>
          </ul>
        </section>

        <section>
          <h2>Texture hardware</h2>
          <ul>
            <li>Legacy from graphics</li>
            <li>Read-only. Always loads through interpolation hardware</li>
            <li>Two-level: Dedicated L1, shared L2 for texture and global loads</li>
          </ul>
          <table class="tbl1" style="width:100%">
            <colgroup>
              <col></col>
              <col></col>
              <col></col>
              <col></col>
              <col></col>
            </colgroup>
            <thead>
              <tr>
                <th></th>
                <th>property</th>
                <th>Fermi</th>
                <th>sm_30</th>
                <th>sm_35</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td  style="background-color:rgba(100,100,100,0.5);"  rowspan="4">L1</td>
                <td>hit latency, clock</td>
                <td>No data</td>
                <td>104</td>
                <td>108</td>
              </tr>
              <tr>
                <td>line size, B</td>
                <td>No data</td>
                <td>128</td>
                <td>128</td>
              </tr>
              <tr>
                <td>size, KB</td>
                <td>8</td>
                <td>12</td>
                <td>4<small style="vertical-align:bottom;">sbp</small>x12</td>
              </tr>
              <tr>
                <td>(set)x(way)</td>
                <td>No data</td>
                <td>4x24</td>
                <td>4x24</td>
              </tr>
              <tr>
                <td rowspan="2" style="border-bottom:none;">L2</td>
                <td>hit latency, clock</td>
                <td>No data</td>
                <td>212</td>
                <td>229</td>
              </tr>
              <tr>
                <td>penalty, clock</td>
                <td>No data</td>
                <td>316</td>
                <td>351</td>
              </tr>
            </tbody>
          </table>
        </section>

        <section>
          <h2>Read-only data cache</h2>
          <p><b>L1 Texture cache</b> is opened for <b>global load</b> bypassing interpolation hardware.
          Supported by sm_35.</p>
          <pre><code class="avrasm">  /*0288*/                <span class="keyword">TEXDEPBAR</span> 0x0;
  /*0290*/                <span class="keyword">LDG</span>.E.64 R8, [R4];
  /*0298*/                <span class="keyword">TEXDEPBAR</span> 0x0;
  /*02a0*/                <span class="keyword">LDG</span>.E.64 R4, [R8];
  /*02a8*/                <span class="keyword">IADD</span> R6, R6, 0x4;
  /*02b0*/                <span class="keyword">TEXDEPBAR</span> 0x0;
  /*02b8*/                <span class="keyword">LDG</span>.E.64 R8, [R4];

  /*02c8*/                <span class="keyword">ISETP</span>.LT.AND P0, PT, R6, R7, PT;
  /*02d0*/                <span class="keyword">TEXDEPBAR</span> 0x0;</code></pre>
          <ul>
            <li>Size is 48&thinsp;KB (4 sub-partitions x 12&thinsp;KB)</li>
            <li>Different warps go through different sub-partitions</li>
            <li>Single warp can use up to 12&thinsp;KB</li>
          </ul>
        </section>

        <section>
          <h2>Constant memory</h2>
          <p>Optimized for <b>uniform</b> access from the warp.</p>
          <img src="images/c1/uniform.svg" class="simple">
          <ul>
            <li>Compile time constants</li>
            <li>Kernel parameters and configurations</li>
            <li>2&ndash;3 layers of caches. Latency: 4&ndash;800 clocks</li>
          </ul>
        </section>

         <section>
          <h2>Load uniform</h2>
          <p>The LDU instruction can employ constant cache hierarchy for each global memory location.
          LDU = load (block-) uniform variable from memory.</p>
          <ul>
            <li>Variable resides in global memory</li>
            <li>Prefix pointer with <code>const</code> keyword</li>
            <li>Memory access must be uniform across all threads in the block (not dependent on threadIdx)</li>
          </ul>
          <pre><code class="cpp"><span class="keyword">__global__</span> void kernel( test_t *g_dst, const test_t *g_src )
{
  const int tid = /**/;
  g_dst[tid] = g_src[0] + g_src[<span class="keyword">blockIdx.x</span>];
}</code></pre>
          <pre><code class="avrasm">  /*0078*/        LDU.E R0, [R4];
  /*0080*/        LDU.E R2, [R2];</code></pre>
        </section>

        <section>
          <h2>Shared memory</h2>
          <p>Banked: Successive 4-byte words placed to successive banks</p>
          <p>sm_1x &ndash; 16x4&thinsp;B, sm_2x &ndash; 32x4&thinsp;B, sm_3x &ndash; 32x64&thinsp;B</p>
          <img src="images/c1/banks.svg" width="90%">
          <p>Atomic operations are done in lock/unlock manner</p>
          <pre><code class="cpp">         (void) atomicAdd( &smem[0], src[threadIdx.x] );</code></pre>
            <pre><code class="avrasm">  /*0050*/        <b>SSY</b> 0x80;
  /*0058*/        <span class="keyword">LDSLK</span> P0, R3, [RZ];
  /*0060*/    @P0 <span class="keyword">IADD</span> R3, R3, R0;
  /*0068*/    @P0 <span class="keyword">STSUL</span> [RZ], R3;
  /*0070*/   @!P0 <span class="keyword">BRA</span> 0x58;
  /*0078*/        NOP.<b>S</b>;</code></pre>
        </section>

        <section>
          <h2>Register spilling</h2>
          <ul>
            <li><b>Local memory</b> refers to memory where registers are spilled</li>
            <li>Physically resides in gmem, but <b>likely cached</b></li>
            <li>A local variable require a cache line for spilling because spilling is done per warp</li>
            <li>Addressing is resolved by the compiler</li>
            <li>Stores are cached in L1</li>
            <li>Analogy with <b>CPU stack variables</b></li>
          </ul>
        </section>

        <section>
          <h2>LDL/STL Access Operation</h2>
          <ul style="list-style-type: none;">
            <li><b>Store writes line to L1</b>
              <ul style="margin-left: 65px;">
                <li>If evicted, then line is written to L2</li>
                <li>The line could also be evicted from L2, in this case it is written to DRAM</li>
              </ul>
            </li>
            <li><b>Load requests line from L1</b>
              <ul style="margin-left: 65px;">
                <li>If a hit, operation is complete</li>
                <li>If a miss, then request the line from L2</li>
                <li>If L2 miss, then request the line from DRAM</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>Final words</h2>
          <ul>
            <li>SM has dedicated LD/ST units to handle memory access</li>
            <li>Global memory accesses are serviced on warp basis</li>
            <li>Coalesced transaction is a transaction that fits cache line</li>
            <li>GPU memory has 2 levels of caches</li>
            <li>One L1 cache line consists of 4 L2-lines. Coalescing unit manages number of L2 lines that is actually required</li>
            <li>64-bit and 128-bit memory transactions are natively supported</li>
            <li>Atomic operations on global memory is done in L2</li>
            <li>Register spilling is fully cached for both reads and writes</li>
          </ul>
        </section>

        <section id="end1">
          <h1>THE END</h1>
          <h6><a href="code_gpu_with_cuda_4.html">next</a></h6>
          <br>
          <br>
          <br>
          <h3>BY <a href="https://github.com/cuda-geek">cuda.geek</a> / 2013&ndash;2015</h3>
        </section>

      </div>
    </div>

    <script src="plugin/reveal/lib/js/head.min.js"></script>
    <script src="plugin/reveal/js/reveal.js"></script>

    <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        slideNumber: true,
        history: true,
        center: false,

        transition: 'slide', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'plugin/reveal/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'plugin/zoom-js/zoom.js', async: true },
          { src: 'plugin/notes/notes.js', async: true }
        ]
      });

    </script>

  </body>
</html>
