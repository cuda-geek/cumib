<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>Pragmatic optimization in modern programming - Mastering compiler optimizations</title>
    <meta name="description" content="Pragmatic optimization in modern programming - Introduction">
    <meta name="author" content="Marina Kolpakova (cuda.geek)">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="plugin/reveal/css/reveal.css">
    <link rel="stylesheet" href="plugin/reveal/css/theme/geek.css" id="theme">
    <link rel="stylesheet" href="css/colors-orange.css">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="plugin/reveal/lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'plugin/reveal/css/print/pdf.css' : 'plugin/reveal/css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!--[if lt IE 9]>
    <script src="plugin/reveal/lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <!-- http://booksite.elsevier.com/9780120884780/Graduate_Lecture_Slides/index.html -->

  <body>
    <div class="reveal">
      <div class="slides">

        <section>
          <h1>Pragmatic optimization</h1>
          <h2>in modern programming</h2>
          <h3>Mastering compiler optimizations</h3>
          <br>
          <br>
          <br>
          <small>Created by
            <a href="http://github.com/cuda-geek">Marina Kolpakova</a>
            for
            <a href="http://www.unn.ru/eng/">UNN</a> / 2015
          </small>
        </section>

        <section>
          <h2>Themes &amp; Contents</h2>
          <ul>
            <li><strong>Pragmatics</strong>
              <ul>
                <li>Ordering optimization approaches</li>
                <li>Demystifying a compiler</li>
                <li><b>Mastering compiler optimizations</b></li>
              </ul>
            </li>
            <li><strong>Computer Architectures</strong>
              <ul>
                <li>Architecture of modern computers</li>
                <li>SIMD extensions</li>
                <li>Specific co-processors</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>Outline</h2>
          <ul>
            <li>Classic taxonomy</li>
            <li>Scope taxonomy</li>
            <li>Code pattern taxonomy</li>
            <li>Examples of machine independent transformations
              <ul>
                <li>Copy propagation</li>
                <li>Constant folding</li>
                <li>...</li>
<!--                 <li>Strength Reduction</li>
                <li>Scalarization</li>
                <li>Common Subexpression Elimination (CSE)</li> -->
              </ul>
            </li>
            <li>Functional body inlining</li>
            <li>Examples of loop optimizations
              <ul>
                <li>Singe-loop optimizations</li>
                <li>Multi-loop optimizations</li>
              </ul>
            </li>
            <li>Auto-vectorization</li>
            <li>Summary</li>
          </ul>
        </section>

        <section>
          <section>
            <h2>Classic taxonomy</h2>
            <ul>
              <li>
                <b>Machine independent transformations</b>
                <ul style="list-style:none;">
                  <li><strong>Applicable across a broad range of machines</strong></li>
                </ul>
                <ol>
                  <li>Eliminate redundant computations</li>
                  <li>Decrease ratio of overhead to real work</li>
                  <li>Eliminate dead code</li>
                  <li>Reduce running time or/and space</li>
                  <li>Specialize code on a context</li>
                  <li>Enable other optimizations</li>
                </ol>
              </li>
              <br/>
              <li>
                <b>Machine dependent transformations</b>
                <ul style="list-style:none;">
                  <li><strong>Capitalize on specific machine properties</strong></li>
                </ul>
                <ol>
                  <li>Manage or hide latency</li>
                  <li>Manage resources (registers, stack)</li>
                  <li>Improve the mapping from IR to this machine</li>
                  <li>Use some exotic instructions (eg VLDM )</li>
                </ol>
              </li>
            </ul>
          </section>

          <section>
            <h2>Scope taxonomy</h2>
            <dl>
              <dt><b>Interprocedural optimizations</b></dt>
              <dd>consider whole translation unit, involve analysis of dataflow and dependency graphs.</dd>
              <br/>
              <dt><b>Intraprocedural optimizations</b></dt>
              <dd>consider whole procedure, involve analysis of dataflow and dependency graphs.</dd>
              <br/>
              <dt><b>Global optimizations</b></dt>
              <dd>consider inter-most code block with the context. Most loop optimizations are belongs to this group </dd>
              <br/>
              <dt><b>Local optimizations</b></dt>
              <dd>consider single code block, limited to straight-line code</dd>
              <br/>
              <dt><b>Peephole optimizations</b></dt>
              <dd>map one or more consecutiveness operators from IR to machine code</dd>
              <br/>
            </dl>
          </section>

          <section>
            <h2>Interprocedural optimizations (IPO)</h2>
            <p>Looks at all routines in order to make optimizations <strong>across routine boundaries</strong>,
              including but not limited to <i>inlining</i> and <i>cloning</i>.It is referred as
              <strong>Interprocedural Analysis (IPA)</strong>, too.</p>
            <ul>
              <li>Compiler can move, optimize, restructure and delete code between procedures<br/>(and files, if LTO is enabled)</li>
              <li><strong>Inlining</strong> &mdash; replacing a subprogram call with the replicated code of the subprogram</li>
              <li><strong>Cloning</strong> &mdash; optimizing logic in the copied routine for the particular call</li>
            </ul>
          </section>

          <section>
            <h2>Code Pattern taxonomy</h2>
            <ul>
              <li>Dependency chains (linear code)</li>
              <li>Branches</li>
              <li><strong>Loop bodies</strong>
                <ul>
                  <li>Single loop</li>
                  <li>Loop and branch</li>
                  <li>Multi-loop</li>
                </ul>
              </li>
              <li>Functional calls to sub-routines</li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>Machine independent transformations</h2>
            <h3>
              <ol>
                <li>Copy propagation</li>
                <li>Constant folding</li>
                <li>Common Subexpression Elimination (CSE)</li>
                <li>Strength Reduction</li>
              </ol>
            </h3>
          </section>

          <section>
            <h2>Machine independent transformations</h2>
            <h3>Copy propagation</h3>
            <ul>
              <li>Eliminates all copies of the variable with the initial value</li>
              <li>Simplifies intermediate representation and as the result<br/> shrinks problem size for further IR
              transformations</li>
              <li>Creates opportunities for death code elimination</li>
            </ul>
            <br/><br/>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="33%">
                    <pre><code class="cpp">
int x = y
int z = 1 + x

</code></pre>
                  </td>
                  <td width="33%">
                    <pre><code class="cpp">
int x = y
int z = 1 + y

</code></pre>
                  </td>
                  <td>
                    <pre><code class="cpp">
int z = 1 + y


</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <p>May be performed in a global as well as local scope. Applicable to any code pattern.</p>
          </section>

          <section>
            <h2>Machine independent transformations</h2>
            <h3>Constant folding</h3>
            <p>Evaluates expressions from the constants in compile time. Expressions could be quite complicated,
            but absence of side effect is always a concern.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%">
                    <pre><code class="cpp">
int a = 37;
int b = (int)log(float(1<<7)*M_PI);
int c = a + b;

</code></pre>
                  </td>
                  <td width="50%">
                    <pre><code class="cpp">
int c = 42;



</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <p>May be performed in global as well as local scope. Applicable to any code pattern.</p>
          </section>

          <section>
            <h2>Machine independent transformations</h2>
            <h3>Common Subexpression Elimination</h3>
            <p>Cache expression result into variable for future use. Sometimes you need to depict them in code, to help
            the compiler detect them.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%">
                    <pre><code class="cpp">
double d = c * (a / b);
double e = (a / b) * 2.0;



</code></pre>
                  </td>
                  <td>
                    <pre><code class="cpp">
double adivb = a / b;

double d = c * adivb;
double e = adivb * 2.0;

</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <p>Usually performed in global scope. Applicable to any code pattern.</p>
          </section>

          <section>
            <h2>Machine independent transformations</h2>
            <h3>Scalarization</h3>
            <p>Replaces branchy code with branch-less analogy.<br/>Usually performed for sequential code chain of loop body to
            allow auto-vectorization.</p>
            <p>Machine-independent, local</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%">
                    <pre><code class="cpp">int branchy(int i)
{
  if (i &gt; 4 && i &lt; 42)
    return 1;
  return 0;
}

int branchless(int i)
{
  return (((unsigned)i) - 5 > 36);
}
</code></pre>
                  </td>
                  <td>
                    <pre><code class="asm">branchy:
  sub w0, w0, #5
  cmp w0, 36
  cset  w0, ls
  ret

branchless:
  sub w0, w0, #5
  cmp w0, 36
  cset  w0, hi
  ret
</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <code>gcc -march=armv8-a+simd -O3 -fopt-info 1.c -S -o 1.s</code>
            <p>Both are compiled to the same instruction sequence</p>
          </section>
        </section>

        <section>
          <section>
            <h2>Machine (in)dependent transformations</h2>
            <h3>Strength Reduction</h3>
            <p>Replaces complex expressions with more simple analogy. Some of this optimizations may be machine
            dependent and rely on a specific feature set implemented in hardware (e.g.
            <strong>built-in detection</strong>)</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%" style="border-bottom: 0;">
                    <pre><code class="cpp">double usePow(double x)
{
  return pow(x, 2.0);
}

</code></pre>
                  </td>
                  <td style="border-bottom: 0;">
                    <pre><code class="armasm">usePow:
  fmdrr d16, r0, r1
  fmuld d16, d16, d16
  fmrrd r0, r1, d16
  bx  lr
</code></pre>
                  </td>
                </tr>
                <tr style="background-color:rgba(0,0,0,0);">
                  <td width="50%">
                    <pre><code class="cpp">float usePowf(float x)
{
  return powf(x, 2.f);
}

</code></pre>
                  </td>
                  <td>
                    <pre><code class="armasm">usePowf:
  fmsr  s15, r0
  fmuls s15, s15, s15
  fmrs  r0, s15
  bx  lr</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <code>gcc -march=armv7-a -mfpu=neon-vfpv4 -mfloat-abi=softfp -mthumb -O3 1.c -S -o 1.s</code>
            <p>Usually performed in local scope for plain dependency chain.</p>
          </section>

          <section>
            <h2>Machine (in)dependent transformations</h2>
            <h3>Strength Reduction (advanced)</h3>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="33%">
                    <pre><code class="cpp">float useManyPowf(
    float a, float b, float c,
    float d, float e, float f,
    float x)
{
  return a * powf(x, 5.f) +
         b * powf(x, 4.f) +
         c * powf(x, 3.f) +
         d * powf(x, 2.f) +
         e * x            +
         f;
}</code></pre>
                  </td>
                  <td width="33%">
                    <pre><code class="armasm">useManyPowf:
  push  {r3, lr}
  fstmfdd sp!,{d8,d9,d10,d11,d12}
  flds  s17, [sp, #56]
  fmsr  s24, r1
  movs  r1, #0
  fmsr  s22, r0
  movt  r1, 16544
  fmrs  r0, s17
  fmsr  s21, r2
  fmsr  s20, r3
  flds  s19, [sp, #48]
  flds  s18, [sp, #52]
  bl  powf(PLT)
  mov r1, #1082130432
  fmsr  s23, r0
  fmrs  r0, s17
  bl  powf(PLT)
</code></pre>
                  </td>
                  <td>
                    <pre><code class="armasm">  movs  r1, #0
  movt  r1, 16448
  fmsr  s16, r0
  fmrs  r0, s17
  bl  powf(PLT)
  fmuls s16, s16, s24
  vfma.f32  s16, s23, s22
  fmsr  s15, r0
  vfma.f32  s16, s15, s21
  fmuls s15, s17, s17
  vfma.f32  s16, s20, s15
  vfma.f32  s16, s19, s17
  fadds s15, s16, s18
  fldmfdd sp!, {d8-d12}
  fmrs  r0, s15
  pop {r3, pc}</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <code>gcc -march=armv7-a -mfpu=neon-vfpv4 -mfloat-abi=softfp -mthumb -O3 1.c -S -o 1.s</code>
          </section>

          <section>
            <h2>Machine (in)dependent transformations</h2>
            <h3>Strength Reduction (manual)</h3>
            <pre><code class="cpp">float applyHornerf(float a, float b, float c, float d, float e, float f, float x)
{
  return ((((a * x + b) * x + c) * x + d) * x + e) * x + f;
}</code></pre>
            <code>gcc -march=armv7-a -mfpu=neon-vfpv4 -mfloat-abi=softfp -mthumb -O3 1.c -S -o 1.s</code>
            <pre><code class="armasm">applyHornerf:
  flds  s15, [sp, #8]
  fmsr  s11, r0
  fmsr  s12, r1
  flds  s14, [sp]
  vfma.f32  s12, s11, s15
  fmsr  s11, r2
  flds  s13, [sp, #4]
  vfma.f32  s11, s12, s15
  fcpys s12, s11
  fmsr  s11, r3
  vfma.f32  s11, s12, s15
  vfma.f32  s14, s11, s15
  vfma.f32  s13, s14, s15
  fmrs  r0, s13
  bx  lr
</code></pre>
          </section>
        </section>

        <!-- <li>Pipeline scheduling – reorder instructions to improve pipeline performance</li> -->

        <section>
          <section>
            <h2>Function body inlining</h2>
            <p>Replace functional call to function body. <strong>Enables all further optimizations.</strong></p>
            <p>Machine-independent &amp; interprocedural.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%">
                    <pre><code class="cpp">int square(int x)
  {
    return x*x;
  }

  for (int i = 0; i < N; i++)
    a[i] = square(i);</code></pre>
                    Becomes
                    <pre><code class="cpp">for (int i = 0; i < N; i++)
    a[i] = i*i;</code></pre>
                  </td>
                  <td>
    <!-- movk - Move 16-bit immediate into register, keeping other bits unchanged. -->
                    <pre><code class="armasm">
  .L2:
    add x2, x4, :lo12:.LANCHOR0
    mov x1, 34464
    mul w3, w0, w0
    movk  x1, 0x1, lsl 16
    str w3, [x2,x0,lsl 2]
    add x0, x0, 1
    cmp x0, x1
    bne .L2



</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <code>gcc -march=armv8-a+nosimd -fstrict-aliasing  -O3 -fopt-info 1.c -S -o 1.s</code>
          </section>
          <section>
            <h2>Function body inlining</h2>
            <p>Let's compile the code with vector extension enabled <strong><code>-march=armv8-a+simd</code></strong></p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%">
                    <pre><code class="cpp">int square(int x)
  {
    return x*x;
  }

  for (int i = 0; i < N; i++)
    a[i] = square(i);</code></pre>
                    Becomes
                    <pre><code class="cpp">for (int i = 0; i < N; i++)
    a[i] = i*i;</code></pre>
                  </td>
                  <td>
                    <pre><code class="armasm">
  add x0, x0, :lo12:.LANCHOR0
  movi  v2.4s, 0x4
  ldr q0, [x1]
  add x1, x0, 397312
  add x1, x1, 2688
.L2:
  mul v1.4s, v0.4s, v0.4s
  add v0.4s, v0.4s, v2.4s
  str q1, [x0],16
  cmp x0, x1
  bne .L2

</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <p>Auto-vectorization is enabled because of possibility to inline function call inside a loop.</p>
          </section>
        </section>

        <!--  -->
        <section>
          <h2>List of loop optimization</h2>
          <ul>
            <li><strong>Single loop (usually the inner)</strong>
              <ul>
                <li>Loop-induction variable elimination</li>
                <li>Hoisting Loop Invariant Code</li>
                <li>Loop unrolling</li>
                <li>Loop Peeling</li>
                <li>Scalarization</li>
                <li>Loop unswitching</li>
                <li>Strip mining</li>

                <!-- out of scope -->
                <!-- <li>Loop skewing</li> -->
                <!-- <li>Unroll-and-jam</li> -->
                <!-- <li>Loop reversal</li> -->
                <!-- <li>Prefetching</li> -->
                <!-- <li>Test promotion in loops</li> -->
                <!-- <li>Software pipelining</li> -->
                <!-- <li>Array Initialization</li> -->
                <!-- <li>Loop Defactorization</li> -->
                <!-- <li>Outer Loop Unrolling</li> -->
                <!--  -->
              </ul>
            </li>
            <li><strong>Multi-loop (nested or detached)</strong>
              <ul>
                <li>Loop fusion/fission</li>
                <li>Loop interchange</li>
                <li>Stride Minimization</li>
                <li>Loop collapse</li>
              </ul>
            </li>
          </ul>
        </section>

        <section>
          <h2>#1: Loop-induction variable elimination</h2>
          <p>In most cases compiler is able to replace address arithmetics with pointer arithmetics.</p>
          <table class="simple">
            <colgroup>
              <col></col>
              <col></col>
            </colgroup>
            <tbody>
              <tr>
                <td width="50%" width="50%" style="border-bottom: 0;">
                  <pre><code class="cpp">void function(int* arr, int len)
{
  for (int i = 0; i < len; i++)
    arr[i] = 1;
}</code></pre>
                </td>
                <td width="50%" style="border-bottom: 0;">
                  <pre><code class="cpp">void function(int* arr, int len)
{
  for (int* p = arr; p < arr + len; p++)
      *p = 1;
}</code></pre>
                </td>
              </tr>
              <tr style="background-color:rgba(0,0,0,0);">
                <td>
                  <pre><code class="armacm">  cmp r1, #0
  ble .L1
  mov r3, r0
  add r0, r0, r1, lsl #2
  movs  r2, #1
.L3:
  str r2, [r3], #4
  cmp r3, r0
  bne .L3
.L1:
  bx  lr</code></pre>
                </td>
                <td>
                  <pre><code class="armasm">
  add r1, r0, r1, lsl #2
  cmp r0, r1
  bcs .L5
  movs  r3, #1
.L8:
  str r3, [r0], #4
  cmp r1, r0
  bhi .L8
.L5:
  bx  lr</code></pre>
                </td>
              </tr>
            </tbody>
          </table>
          <code>gcc -march=armv7-a -mfpu=neon-vfpv4 -mfloat-abi=softfp -mthumb -O1 1.c -S -o 1.s</code>
          <p>
            <strong>Most hand-written pointer optimizations do not make sense with usage optimization levels
            higher than O0.</strong>
          </p>
        </section>

        <section>
          <h2>#2: Hoisting Loop Invariant Code</h2>
          <p>The goal of <b>hoisting</b> — also called <b>loop-invariant code motion</b> — is to avoid recomputing
          loop-invariant code each time through the body of a loop.</p>
         <table class="simple">
            <colgroup>
              <col></col>
              <col></col>
            </colgroup>
            <tbody>
              <tr>
                <td width="50%" width="50%" style="border-bottom: 0;">
                  <pre><code class="cpp">void scale(double* X, double* Y, int len)
{
  for (int i = 0; i < len; i++)
    Y[i] = X[i] * exp(sqrt(M_PI/2));
}

</code></pre>
                </td>
                <td width="50%" style="border-bottom: 0;">
                  <pre><code class="cpp">void scale(double* X, double *Y, int len)
{
  double factor = exp(sqrt(M_PI/2));
  for (int i = 0; i < len; i++)
    Y[i] = X[i] * factor;
}</code></pre>
                </td>
              </tr>
              <tr style="background-color:rgba(0,0,0,0);">
                <td>
                  <pre><code class="armacm">  fldd  d17, .L5
.L3:
  fldmiad r3!, {d16}
  fmuld d16, d16, d17
  fstmiad r1!, {d16}
  cmp r3, r0
  bne .L3
.L1:
  bx  lr
.L5:
  .word 2911864813
  .word 1074529267
</code></pre>
                </td>
                <td>
                  <pre><code class="armasm">  fldd  d17, .L11
.L9:
  fldmiad r3!, {d16}
  fmuld d16, d16, d17
  fstmiad r1!, {d16}
  cmp r3, r0
  bne .L9
.L7:
  bx  lr
.L11:
  .word 2911864813
  .word 1074529267</code></pre>
                </td>
              </tr>
            </tbody>
          </table>
          <code>gcc -march=armv7-a -mfpu=neon-vfpv4 -mfloat-abi=softfp  -mthumb -O1 1.c -S -o 1.s</code>
        </section>

        <!--  -->

        <section>
          <section>
            <h2>#3: Loop unswitching</h2>
            <p>Moves loop-invariant conditionals or switches which are independent of the loop index out of
            the loop. Increases instruction level parallelism, enables further optimizations.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%">
                   <pre><code class="cpp">for (int i = 0; i < len; i++)
{
  if (a > 32)
    arr[i] = a;
  else
    arr[i] = 42;
}
</code></pre>
                    Becomes
                   <pre><code class="cpp">if (a > 32)
{
  for (int i = 0; i < len; i++)
    arr[i] = a;
}
else
{
  for (int i = 0; i < len; i++)
    arr[i] = 42;
}</code></pre>
                  </td>
                  <td>
                    <pre><code class="armasm">cmp w1, wzr
  ble .L1
  cmp w2, 32
  bgt .L6
  mov x2, 0
  mov w3, 42
.L4:
  str w3, [x0,x2,lsl 2]
  add x2, x2, 1
  cmp w1, w2
  bgt .L4
.L1:
  ret
.L6:
  mov x3, 0
.L3:
  str w2, [x0,x3,lsl 2]
  add x3, x3, 1
  cmp w1, w3
  bgt .L3
  ret</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <code>-gcc -march=armv8-a+simd -fno-tree-vectorize -O3 -fopt-info 1.c -S -o 1.s</code>
            <small>auto-vectorization is disabled just to make example readable.</small>
          </section>

          <section>
            <h2>Loop peeling</h2>
            <p>A small number of iterations from the beginning or end of a loop taken out of the loop and executed
            separately which eliminates if-statements and makes the loop more suitable for vectorization. In some
            cases can be performed by the compiler on high optimization levels.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%">
                   <pre><code class="cpp">
for (int i = 0; i &lt; len; i++)
{
  if (i==0)
    b[i] = a[i+1];
  else if(i== len-1 )
    b[i] = a[i-1];
  else
    b[i] = a[i+1] + a[i-1];
}

</code></pre>
                  </td>
                  <td>
                   <pre><code class="cpp">
b[0] = a[0];

for (int i = 0; i &lt; len; i++)
  [i] = a[i+1] + a[i-1];

b[len-1] = a[len-1];




</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <p>IFor the example below both tested compilers: gcc 4.9 as well as the clang 3.5
            <strong>won't</strong> perform this optimization. Make sure that compiler was able to apply optimization
            to such a code pattern or implement this optimization manually.</p>
          </section>

          <section>
            <h2>Advanced unswitching: Sentinels</h2>
            <p><b>Sentinels</b> are special dummy values placed in a data structure <br/>which are added to simplify the logic
            of handling boundary conditions <br/>(in particular, handling of loop-exit tests
            or elimination out-of-bound checks).</p>

            <p>Let's assume that array <strong><code>a</code></strong> contains two extra elements:<br/> one &mdash; at the left,
             another &mdash; at the right. The code can be rewritten as follows.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td width="50%">
                   <pre><code class="cpp">
for (int i = 0; i &lt; len; i++)
{
  if (i==0)
    b[i] = a[i+1];
  else if(i== len-1 )
    b[i] = a[i-1];
  else
    b[i] = a[i+1] + a[i-1];
}

</code></pre>
                  </td>
                  <td>
                   <pre><code class="cpp">
// setup constants
a[-1]  = 0;
a[len] = 0;

for (int i = 0; i &lt; len; i++)
  [i] = a[i+1] + a[i-1];




</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
            <p><strong>This optimization cannot be performed by the compiler <br/>because require changes in use of
            data structures</strong></p>
          </section>
        </section>

<!--             <ul class="none">
              <li>Before
                <pre style="display:inline;"><code class="cpp">bool overflow(uint64_t* A, size_t n)
{
  uint64_t sum = 0;
  for (size_t i = 0; i < n; ++i)
  {
    sum += A[i];
    if (sum < A[i])
      return true;
  }
  return  false;
}</code></pre>
              </li>
              <li>After
                  <pre style="display:inline;"><code class="cpp">bool overflow(uint64_t* A, size_t n)
{
  A[n] = UINT64_MAX, A[n+1] = 0;
  size_t i = 0; uint64_t sum = A[0];
  while ( sum >= A[i])
    sum += A[++i];

  return (i < n);
}</code></pre>
              </li>
            </ul> -->

<!--  -->
        <section>
          <h2>#3: Loop unrolling</h2>
          <p>Generates multiple copies of the code for the loop body, reduces number of branches and groups more
          instructions together to enable more efficient instruction pipelining. Best candidates are innermost loops
          with limited control flow.</p>
          <ul class="none:">
            <li>Before
              <pre><code class="cpp">
for (int i = 0 ; i < N; i++)
  h[p[i]]++;

</code></pre>
            </li>
            <li>After
              <pre><code class="cpp">
for (int i = 0 ; i <= N-4; i+=4)
{
  int idx0 = p[i+0]; int idx1 = p[i+1];
  int idx2 = p[i+2]; int idx3 = p[i+3];

  h[idx0]++; h[idx1]++;
  h[idx2]++; h[idx3]++;
}

</code></pre>
            </li>
          </ul>
        </section>

        <section>
          <h2>Outer Loop unrolling</h2>
          <p>Usually it is used to reduce number of loads and stores on inner loops with invariants, introduce reuse of
          loaded values which are kept in registers or caches. Complicated for compilers</p>
          <p>dot product example - process 2 lines</p>
          <p>test-flags example</p>
        </section>

        <section>
          <h2>#5: Strip mining</h2>
          <p>Also called as blocking or tiling.</p>
          <ul class="none:">
            <li>Before
              <pre><code>
for (int i = 0; i < N; i++)
{
  for (int j = 0; j < N; j++)
  {
    A[i][j] = A[i][j] + B[j][i];
  }
}
</code></pre>
            </li>
            <li>After
              <pre><code>
for (int i = 0; i < N; i += block_size)
{
  for (int j = 0; j < N; j += block_size)
  {
    for (int ii = i; ii < i + block_size; ii++)
    {
      for (int jj = j; jj < j + block_size; jj++)
      {
        A[ii][jj] = A[ii][jj] + B[jj][ii];
      }
    }
  }
}
</code></pre>
            </li>
          </ul>
        </section>

        <section>
          <h2>#6: Loop Interchange</h2>
            <p>It is usually done for stride Minimization</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td>
                    <pre><code class="cpp">
for (int j = 0; j &lt; height; j++)
{
  for (int i = 0; i &lt; width; i++)
  {
    if (img[j * width + i] &gt; 0)
    {
      count++;
    }
  }
}
                    </code></pre>
                  </td>
                  <td>
                    <pre><code class="cpp">
for (int i = 0; i &lt; width; i++)
{
  for (int j = 0; j &lt; height; j++)
  {
    if (img[j * width + i] &gt; 0)
    {
      count++;
    }
  }
}
                    </code></pre>
                  </td>
              </tbody>
            </table>
        </section>

        <section>
          <h2>#7: Loop Fusion / Fission</h2>
          <ul class="none">
            <li>Loop <b>fission</b> breaks up a complicated loop into multiple smaller loops, iterating over the same
            index range which may help to achieve better locality of reference and reduce register pressure. Fission
            results in smaller cache footprint.
              <pre><code class="cpp">for (size_t i = 0; i < n; ++i)
  b[i] = a[i] + 1.f;

for (size_t i = 0; i < n; ++i)
  c[i] = b[i] / 2.f;

for (size_t i = 0; i < n; ++i)
  d[i] = 1.f / c[i];
</code></pre>
            </li>
            <li>Loop <b>fusion</b> combines multiple loops operating over the same index range into one single loop
            which may lead to better locality of reference, but it may increase register pressure as well. Fusion results
            in fewer total memory references.
              <pre><code class="cpp">for (size_t i = 0; i < n; ++i)
{
  b[i] = a[i] + 1.f;
  c[i] = b[i] / 2.f;
  d[i] = 1.f / c[i];
}
</code></pre>
            </li>
          </ul>
        </section>

        <section>
          <h2>#8: Loop collapse</h2>
            <p>Reduces loop nesting and overhead on address computations, helps auto-vectorization.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td>
                    <pre><code class="cpp">
for (int j = 0; j &lt; height; j++)
{
  for (int i = 0; i &lt; width; i++)
  {
    if (img[j * width + i] &gt; 0)
    {
      count++;
    }
  }
}
                    </code></pre>
                  </td>
                  <td>
                    <pre><code class="cpp">
for (int j = 0; j &lt; height * width; j++)
{
  if (img[j] &gt; 0)
    count++;
}
                    </code></pre>
                  </td>
              </tbody>
            </table>
        </section>

        <section>
          <section>
            <h2>Filling and copying memory blocks</h2>
            <p>Uses the library functions <code>memset</code> and <code>memcpy</code> to initialize and copy memory blocks.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td style="width:50%">
                    <pre><code class="cpp">static char a[100000];
static char b[100000];

static int at(int idx, char val)
{
  if (idx&gt;=0 &amp;&amp; idx&lt;100000)
    a[idx] = val;
}

int main()
{
  int i;
  for (i=0; i&lt;100000; ++i) a[i]=42;
  for (i=0; i&lt;100000; ++i) at(i,-1);
  for (i=0; i&lt;100000; ++i) b[i] = a[i];
}
                    </code></pre>
                  </td>
                  <td>
                    <pre><code style="padding-left:20px;" class="x86asm">main:
.LFB1:
  .cfi_startproc
  subq  $8, %rsp
  .cfi_def_cfa_offset 16
  movl  $100000, %edx
  movl  $42, %esi
  movl  $a, %edi
  call  memset
  movl  $100000, %edx
  movl  $255, %esi
  movl  $a, %edi
  call  memset
  movl  $100000, %edx
  movl  $a, %esi
  movl  $b, %edi
  call  memcpy
  addq  $8, %rsp
  .cfi_def_cfa_offset 8
  ret
  .cfi_endproc</code></pre>
                  </td>
                </tbody>
              </table>
            </tr>
          </section>

          <section>
            <h2>Filling and copying memory blocks</h2>
            <p>The same picture, if the code is compiled for ARM target.</p>
            <table class="simple">
              <colgroup>
                <col></col>
                <col></col>
              </colgroup>
              <tbody>
                <tr>
                  <td style="width:50%">
                    <pre><code class="cpp">static char a[100000];
static char b[100000];

static int at(int idx, char val)
{
  if (idx&gt;=0 &amp;&amp; idx&lt;100000)
    a[idx] = val;
}

int main()
{
  int i;
  for (i=0; i&lt;100000; ++i) a[i]=42;
  for (i=0; i&lt;100000; ++i) at(i,-1);
  for (i=0; i&lt;100000; ++i) b[i] = a[i];
}
                    </code></pre>
                  </td>
                  <td>
                    <pre><code style="padding-left:20px;" class="x86asm">main:
  ldr r3, .L3
  mov r1, #42
  stmfd sp!, {r4, lr}
  add r3, pc, r3
  movw  r4, #34464
  movt  r4, 1
  mov r0, r3
  mov r2, r4
  bl  memset(PLT)
  mov r2, r4
  mov r1, #255
  bl  memset(PLT)
  mov r2, r4
  mov r3, r0
  ldr r0, .L3+4
  mov r1, r3
  add r0, pc, r0
  add r0, r0, #1792
  bl  memcpy(PLT)
  ldmfd sp!, {r4, pc}</code></pre>
                  </td>
                </tr>
              </tbody>
            </table>
          </section>
        </section>

        <section>
          <section>
            <h2>Auto-vectorization</h2>
            <ul>
              <li>Machine code generation that takes advantage of vector instructions.</li>
              <li>Most of all modern architectures have vector extensions (as a co-processor or as specialized pipes)
                <ul>
                  <li>MMX, SSE, SSE2, SSE4, AVX, AVX-512</li>
                  <li>AltiVec, VSX</li>
                  <li>ASIMD (NEON), MSA</li>
                </ul>
              </li>
              <li>Enabled by inlining, unrolling, fusion, software pipelining, inter-procedural optimization, etc.</li>
            </ul>
          </section>
          <section>
            <h2>Auto-vectorization example</h2>
            <pre><code class="cpp">void vectorizeMe(float *a, float *b, int N)
{
  int i;
  for (i = 0; i < N; i++)
    a[i] += b[i];
}</code></pre>
            <code>gcc -march=armv7-a -mfpu=neon-vfpv4 -mfloat-abi=softfp -mthumb -O3 -fopt-info-missed 1.c -S -o 1.s</code>
            <pre><code class="armasm">.L3:
  fldmias r1!, {s14}
  flds  s15, [r0]
  fadds s15, s15, s14
  fstmias r0!, {s15}
  cmp r0, r2
  bne .L3</code></pre>
            <p>NEON does not support full IEEE 754, so gcc cannot vectorize the loop, what it told us</p>
            <blockquote style="width:100%">1.c:64:3: note: not vectorized: relevant stmt not supported: _13 = _9 + _12;
</blockquote>
          </section>
          <section>
            <h2>Auto-vectorization example</h2>
            <p>But armv8-a does support, let's check it!</p>
            <pre><code class="cpp">void vectorizeMe(float *a, float *b, int N)
{
  int i;
  for (i = 0; i < N; i++)
    a[i] += b[i];
}</code></pre>
            <code>gcc -march=armv7-a -mfpu=neon-vfpv4 -mfloat-abi=softfp -mthumb -O3 -fopt-info-missed 1.c -S -o 1.s</code>
            <pre><code class="armasm">.L6:
  ldr q1, [x3],16
  add w6, w6, 1
  ldr q0, [x7],16
  cmp w6, w4
  fadd  v0.4s, v0.4s, v1.4s
  str q0, [x8],16
  bcc .L6</code></pre>
            <p>Optimizer reports:</p>
            <blockquote style="width:100%">1.c:64:3: note: loop vectorized</blockquote>
          </section>
          <section>
            <h2>Detailed analysis</h2>
            <p>Full optimizer's report:</p>
            <blockquote  style="width:100%;text-align: left;">
              1.c:66:3: note: loop vectorized<br/>
              1.c:66:3: note: loop versioned for vectorization because of possible aliasing<br/>
              1.c:66:3: note: loop peeled for vectorization to enhance alignment<br/>
              1.c:66:3: note: loop with 3 iterations completely unrolled<br/>
              1.c:61:6: note: loop with 3 iterations completely unrolled<br/>
            </blockquote>
            <pre><code class="cpp">void vectorizeMe(float* __restrict a_, float* __restrict b_, int N)
{
  int i;
  float *a = __builtin_assume_aligned(a_, 16);
  float *b = __builtin_assume_aligned(b_, 16);
  for (i = 0; i < N; i++)
    a[i] += b[i];
}</code></pre>
            <blockquote  style="width:100%;text-align: left;">
              1.c:66:3: note: loop vectorized<br/>
              1.c:66:3: note: loop with 3 iterations completely unrolled<br/>
            </blockquote>
            <strong>Keywords may help, but are not necessary nowadays.</strong>
          </section>
        </section>


        <section>
          <h2>Summary</h2>
          <ul>
            <li><strong>Are you still optimizing debug versions?</strong> Learn a compiler well and stick with it!</li>
          </ul>
        </section>

        <section id="end1">
          <h1>THE END</h1>
          <img class="simple" src="images/popt/infinity.png">
          <h4><a href="https://github.com/cuda-geek">Marina Kolpakova</a> / 2015</h4s>
        </section>

      </div>

    </div>

    <script src="plugin/reveal/lib/js/head.min.js"></script>
    <script src="plugin/reveal/js/reveal.js"></script>

    <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        slideNumber: true,
        history: true,
        center: false,

        width: 960,
        height: 720,

        transition: 'slide', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
          { src: 'plugin/reveal/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: 'plugin/zoom-js/zoom.js', async: true },
          { src: 'plugin/notes/notes.js', async: true }
        ]
      });

    </script>

  </body>
</html>
